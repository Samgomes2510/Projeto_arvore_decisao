# ğŸŒ³ Projeto de ClassificaÃ§Ã£o com Ãrvore de DecisÃ£o

Este projeto tem como objetivo aplicar o algoritmo de *Ãrvore de DecisÃ£o* para prever a aprovaÃ§Ã£o de crÃ©dito de clientes com base em caracterÃ­sticas prÃ©-definidas. A atividade foi realizada como parte do curso de AnÃ¡lise de Dados.

## ğŸ“Œ Objetivo

Desenvolver um modelo de Machine Learning supervisionado usando o algoritmo de Ãrvore de DecisÃ£o, treinando e avaliando o desempenho da classificaÃ§Ã£o entre clientes que terÃ£o ou nÃ£o crÃ©dito aprovado.

## ğŸ§  Modelo Utilizado

- *Ãrvore de DecisÃ£o* (DecisionTreeClassifier) da biblioteca sklearn.

## ğŸ“Š Etapas do Projeto

1. *ImportaÃ§Ã£o e exploraÃ§Ã£o dos dados*
   - Leitura da base de dados.
   - VerificaÃ§Ã£o de valores ausentes.
   - AnÃ¡lise estatÃ­stica e visual (grÃ¡ficos, correlaÃ§Ãµes, etc).

2. *PrÃ©-processamento dos dados*
   - CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas.
   - SeparaÃ§Ã£o entre variÃ¡veis preditoras (X) e variÃ¡vel alvo (y).
   - DivisÃ£o entre dados de treino e teste.

3. *Treinamento do modelo*
   - UtilizaÃ§Ã£o de DecisionTreeClassifier.
   - Ajuste aos dados de treino (fit).

4. *AvaliaÃ§Ã£o do modelo*
   - AcurÃ¡cia e Recall nos dados de treino e teste.
   - Matriz de confusÃ£o.
   - ComparaÃ§Ã£o entre desempenho nos conjuntos de treino e teste.

## ğŸ§ª MÃ©tricas de AvaliaÃ§Ã£o

- *AcurÃ¡cia*
- *Recall (macro)*
- *Matriz de ConfusÃ£o*

Essas mÃ©tricas ajudaram a verificar o desempenho do modelo e identificar possÃ­veis overfittings.

## ğŸ” Principais Insights

- O modelo teve melhor desempenho nos dados de treino do que no teste, indicando um leve overfitting.
- A anÃ¡lise da matriz de confusÃ£o demonstrou que o modelo acerta mais as classes majoritÃ¡rias.
- Ajustes nos hiperparÃ¢metros podem melhorar a generalizaÃ§Ã£o.

## ğŸ›  Tecnologias Utilizadas

- Python
- Pandas
- Numpy
- Scikit-learn
- Matplotlib / Seaborn (para visualizaÃ§Ãµes)

## ğŸ“ OrganizaÃ§Ã£o do Projeto

```bash
ğŸ“‚ projeto-arvore-decisao
â”‚
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“Š dataset.csv
â”œâ”€â”€ ğŸ““ notebook_decision_tree.ipynb
